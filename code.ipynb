{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/monperrus/.env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/monperrus/.env/lib/python3.10/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 259/259 [00:00<00:00, 79.0kB/s]\n",
      "vocab.json: 100%|██████████| 497k/497k [00:00<00:00, 1.49MB/s]\n",
      "merges.txt: 100%|██████████| 277k/277k [00:00<00:00, 50.8MB/s]\n",
      "tokenizer.json: 100%|██████████| 840k/840k [00:00<00:00, 7.59MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 125kB/s]\n",
      "/root/monperrus/.env/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1595: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "config.json: 100%|██████████| 903/903 [00:00<00:00, 1.33MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 457M/457M [00:11<00:00, 40.2MB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codeparrot/codeparrot-small\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"codeparrot/codeparrot-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_function(docstring):\n",
    "    \"\"\"\n",
    "    Creates a function with the specified docstring.\n",
    "\n",
    "    Parameters:\n",
    "    docstring (str): The docstring to embed in the newly created function.\n",
    "\n",
    "    Returns:\n",
    "    function: A new function with the specified docstring.\n",
    "    \"\"\"\n",
    "    # Define the function code as a string, inserting the docstring dynamically\n",
    "    function_code = f'''\n",
    "def function():\n",
    "    \"\"\"{docstring}\"\"\"\n",
    "    '''\n",
    "    return function_code\n",
    "\n",
    "# Example usage\n",
    "# print(create_function(function_desc))\n",
    "\n",
    "def print_output(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    attention_mask = tokenizer(input_text, return_tensors=\"pt\")[\"attention_mask\"]\n",
    "\n",
    "    # Generate output with attention mask\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask, max_length=500, num_beams=5,early_stopping=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # Decode the output\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def function():\n",
      "    \"\"\"Connect to the database skypeDB and execute the command \"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\"\"\"\n",
      "    \n",
      "def main():\n",
      "    \"\"\"Connect to the database skypeDB and execute the command \"SELECT displayname, skypename, city, country, phone_mobile, birthday FROM Contacts;\"\"\"\n",
      "    skypeDB = skype.SkypeDB()\n",
      "    cursor = skypeDB.cursor()\n",
      "    cursor.execute(\"SELECT displayname, skypename, city, country, phone_mobile, birthday FROM Contacts\")\n",
      "    for row in cursor:\n",
      "        displayname = row[0]\n",
      "        skypename = row[1]\n",
      "        city = row[2]\n",
      "        country = row[3]\n",
      "        phone_mobile = row[4]\n",
      "        birthday = row[5]\n",
      "        print displayname, skypename, city, country, phone_mobile, birthday\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "# -*- coding: utf-8 -*-\n",
      "#\n",
      "# Copyright (C) Pootle contributors.\n",
      "#\n",
      "# This file is a part of the Pootle project. It is distributed under the GPL3\n",
      "# or later license. See the LICENSE file for a copy of the license and the\n",
      "# AUTHORS file for copyright and authorship information.\n",
      "\n",
      "from django.conf import settings\n",
      "from django.contrib.auth.models import User\n",
      "from django.contrib.contenttypes.models import ContentType\n",
      "from django.core.urlresolvers import reverse\n",
      "from django.db import models\n",
      "from django.utils.translation import ugettext_lazy as _\n",
      "from django.utils.translation import ugettext_lazy as _lazy\n",
      "from django.utils.translation import ugettext_lazy_lazy as _lazy_\n",
      "from django.utils.translation import ugettext_lazy_lazy as _lazy_\n",
      "from django.utils.translation import ugettext_lazy as _lazy_\n",
      "from django.utils.translation import ugettext_lazy_lazy as _lazy_\n",
      "from django.utils.translation import ugettext_lazy as _lazy_\n",
      "from django.utils.translation import ugettext_lazy as _lazy_\n",
      "from django.utils.translation import ugettext_lazy as _lazy_\n",
      "from django.utils.translation import ugettext_lazy as _lazy_\n",
      "from django.utils.translation import ugettext_lazy\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"Connect to the database skypeDB and execute the command \"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\"\"\"\n",
    "input_text = create_function(input_text)\n",
    "\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "attention_mask = tokenizer(input_text, return_tensors=\"pt\")[\"attention_mask\"]\n",
    "\n",
    "beam_output = model.generate(input_ids, attention_mask=attention_mask, max_length=500, num_beams=2, early_stopping=True)\n",
    "# Decode the output\n",
    "decoded_beam_output = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
    "print(decoded_beam_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 240/240 [00:00<00:00, 447kB/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 40.6MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 48.5MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 16.8MB/s]\n",
      "added_tokens.json: 100%|██████████| 1.00k/1.00k [00:00<00:00, 2.32MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 244kB/s]\n",
      "config.json: 100%|██████████| 999/999 [00:00<00:00, 2.30MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 797M/797M [00:08<00:00, 97.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350m-mono\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"Salesforce/codegen-350m-mono\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_function(docstring):\n",
    "    \"\"\"\n",
    "    Creates a function with the specified docstring.\n",
    "\n",
    "    Parameters:\n",
    "    docstring (str): The docstring to embed in the newly created function.\n",
    "\n",
    "    Returns:\n",
    "    function: A new function with the specified docstring.\n",
    "    \"\"\"\n",
    "    # Define the function code as a string, inserting the docstring dynamically\n",
    "    function_code = f'''\n",
    "def function():\n",
    "    \"\"\"{docstring}\"\"\"\n",
    "    '''\n",
    "    return function_code\n",
    "\n",
    "# Example usage\n",
    "# print(create_function(function_desc))\n",
    "\n",
    "def gen_output(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    attention_mask = tokenizer(input_text, return_tensors=\"pt\")[\"attention_mask\"]\n",
    "\n",
    "    # Generate output with attention mask\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask, max_length=500,num_beams=2,early_stopping=True,pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # Decode the output\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return decoded_output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def function():\n",
      "    \"\"\"Connect to the database skypeDB and execute the command \"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\"\"\"\n",
      "    conn = sqlite3.connect(\"skypeDB.db\")\n",
      "    c = conn.cursor()\n",
      "    c.execute(\"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\")\n",
      "    rows = c.fetchall()\n",
      "    conn.commit()\n",
      "    conn.close()\n",
      "    return rows\n",
      "\n",
      "def function_2():\n",
      "    \"\"\"Connect to the database skypeDB and execute the command \"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\"\"\"\n",
      "    conn = sqlite3.connect(\"skypeDB.db\")\n",
      "    c = conn.cursor()\n",
      "    c.execute(\"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\")\n",
      "    rows = c.fetchall()\n",
      "    conn.commit()\n",
      "    conn.close()\n",
      "    return rows\n",
      "\n",
      "def function_3():\n",
      "    \"\"\"Connect to the database skypeDB and execute the command \"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\"\"\"\n",
      "    conn = sqlite3.connect(\"skypeDB.db\")\n",
      "    c = conn.cursor()\n",
      "    c.execute(\"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\")\n",
      "    rows = c.fetchall()\n",
      "    conn.commit()\n",
      "    conn.close()\n",
      "    return rows\n",
      "\n",
      "def function_4():\n",
      "    \"\"\"Connect to the database skypeDB and execute the command \"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\"\"\"\n",
      "    conn = sqlite3.connect(\"skypeDB.db\")\n",
      "    c = conn.cursor()\n",
      "    c.execute(\"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\")\n",
      "    rows = c.fetchall()\n",
      "    conn.commit()\n",
      "    conn.close()\n",
      "    return rows\n",
      "\n",
      "def function_5():\n",
      "    \"\"\"Connect\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"Connect to the database skypeDB and execute the command \"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\"\"\"\n",
    "output = gen_output(create_function(input_text))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def function():\n",
      "    \"\"\"Given a src, tgt and ack send syn and ack packets to tgt with source port 513 and destination port 514\"\"\"\n",
      "    src_port = 513\n",
      "    tgt_port = 514\n",
      "    ack_port = 514\n",
      "    src_ip = \"10.0.0.1\"\n",
      "    tgt_ip = \"10.0.0.2\"\n",
      "    ack_ip = \"10.0.0.3\"\n",
      "    src_mac = \"00:00:00:00:00:01\"\n",
      "    tgt_mac = \"00:00:00:00:00:02\"\n",
      "    ack_mac = \"00:00:00:00:00:03\"\n",
      "    src_ip_v6 = \"2001:db8::1\"\n",
      "    tgt_ip_v6 = \"2001:db8::2\"\n",
      "    ack_ip_v6 = \"2001:db8::3\"\n",
      "    src_mac_v6 = \"00:00:00:00:00:04\"\n",
      "    tgt_mac_v6 = \"00:00:00:00:00:05\"\n",
      "    ack_mac_v6 = \"00:00:00:00:00:06\"\n",
      "    src_ip_v6_v6 = \"2001:db8::1\"\n",
      "    tgt_ip_v6_v6 = \"2001:db8::2\"\n",
      "    ack_ip_v6_v6 = \"2001:db8::3\"\n",
      "    src_mac_v6_v6 = \"00:00:00:00:00:07\"\n",
      "    tgt_mac_v6_v6 = \"00:00:00:00:00:08\"\n",
      "    ack_mac_v6_v6 = \"00:00:00:00:00:09\"\n",
      "    src_ip_v6_v6_v6 = \"2001:db8::1\"\n",
      "    tgt_ip_v6_v6_v6 = \"2001:db8::2\"\n",
      "    ack_ip_v6_v6_v6 = \"2001:db8::3\"\n",
      "    src_mac_v6_\n",
      "==========EXPECTED OUTPUT==============\n",
      "\n",
      "\n",
      "def spoofConn(src, tgt, ack): \\n     IPlayer = IP(src=src, dst=tgt) \\n     TCPlayer = TCP(sport=513, dport=514) \\n     synPkt = IPlayer / TCPlayer \\n     send(synPkt) \\n  \\n     IPlayer = IP(src=src, dst=tgt) \\n     TCPlayer = TCP(sport=513, dport=514, ack=ack) \\n     ackPkt = IPlayer / TCPlayer \\n     send(ackPkt) \\n\n"
     ]
    }
   ],
   "source": [
    "# input_text = \"\"\"Connect to the database skypeDB and execute the command \"SELECT displayname, skypename, city, country,phone_mobile, birthday FROM Contacts;\"\"\"\n",
    "\n",
    "def get_line(file_path, line_number):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for current_line_number, line in enumerate(file, start=1):\n",
    "                if current_line_number == line_number:\n",
    "                    return line.strip()  # Return the line without trailing newline\n",
    "        return \"Error: Line number exceeds the total number of lines in the file.\"\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: The file was not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "def compare(line_num):\n",
    "    in_path = '/root/monperrus/violent-python/function/python-train.in'\n",
    "    out_path = '/root/monperrus/violent-python/function/python-train.out'\n",
    "    func_desc = get_line(in_path,line_num)\n",
    "    output = gen_output(create_function(func_desc))\n",
    "    print(output)\n",
    "\n",
    "    print(\"\\n\\n==========EXPECTED OUTPUT==============\\n\\n\")\n",
    "\n",
    "    expected_output = get_line(out_path,line_num)\n",
    "    print(expected_output)\n",
    "\n",
    "compare(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def function():\n",
      "    \"\"\"Given a string, search it on google ajax apis and return a json\"\"\"\n",
      "    url = \"https://www.googleapis.com/youtube/v3/search\"\n",
      "    params = {\"part\": \"snippet\", \"q\": query, \"key\": API_KEY}\n",
      "    response = requests.get(url, params=params)\n",
      "    response.raise_for_status()\n",
      "    data = response.json()\n",
      "    return data\n",
      "\n",
      "\n",
      "def get_video_id(video_id):\n",
      "    \"\"\"Given a video id, return the video id\"\"\"\n",
      "    url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
      "    params = {\"part\": \"snippet\", \"id\": video_id, \"key\": API_KEY}\n",
      "    response = requests.get(url, params=params)\n",
      "    response.raise_for_status()\n",
      "    data = response.json()\n",
      "    return data[\"items\"][0][\"id\"][\"videoId\"]\n",
      "\n",
      "\n",
      "def get_video_title(video_id):\n",
      "    \"\"\"Given a video id, return the video title\"\"\"\n",
      "    url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
      "    params = {\"part\": \"snippet\", \"id\": video_id, \"key\": API_KEY}\n",
      "    response = requests.get(url, params=params)\n",
      "    response.raise_for_status()\n",
      "    data = response.json()\n",
      "    return data[\"items\"][0][\"snippet\"][\"title\"]\n",
      "\n",
      "\n",
      "def get_video_description(video_id):\n",
      "    \"\"\"Given a video id, return the video description\"\"\"\n",
      "    url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
      "    params = {\"part\": \"snippet\", \"id\": video_id, \"key\": API_KEY}\n",
      "    response = requests.get(url, params=params)\n",
      "    response.raise_for_status()\n",
      "    data = response.json()\n",
      "    return data[\"items\"][0][\"snippet\"][\"description\"]\n",
      "\n",
      "\n",
      "\n",
      "==========EXPECTED OUTPUT==============\n",
      "\n",
      "\n",
      "def google(search_term): \\n     ab = anonBrowser() \\n  \\n     search_term = urllib.quote_plus(search_term) \\n     response = ab.open('http://ajax.googleapis.com/'+      'ajax/services/search/web?v=1.0&q='+ search_term) \\n     objects = json.load(response) \\n\n"
     ]
    }
   ],
   "source": [
    "in_path = '/root/monperrus/violent-python/function/python-train.in'\n",
    "out_path = '/root/monperrus/violent-python/function/python-train.out'\n",
    "line_num = 14\n",
    "func_desc = get_line(in_path,line_num)\n",
    "output = gen_output(create_function(func_desc))\n",
    "print(output)\n",
    "\n",
    "print(\"\\n\\n==========EXPECTED OUTPUT==============\\n\\n\")\n",
    "\n",
    "expected_output = get_line(out_path,line_num)\n",
    "print(expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylev\n",
    "\n",
    "def edPercent(string1, string2):\n",
    "    edit_distance = pylev.levenshtein(string1, string2)\n",
    "    max_len = max(len(string1), len(string2))\n",
    "    similarity = (1 - (edit_distance / max_len)) * 100\n",
    "    return round(similarity, 2)\n",
    "\n",
    "distance = pylev.levenshtein(output, expected_output)\n",
    "p_distance = edPercent(output, expected_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.92"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 2.16k/2.16k [00:00<00:00, 603kB/s]\n",
      "tokenizer.model: 100%|██████████| 4.24M/4.24M [00:00<00:00, 21.4MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.5M/17.5M [00:00<00:00, 34.4MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 888/888 [00:00<00:00, 1.15MB/s]\n",
      "config.json: 100%|██████████| 694/694 [00:00<00:00, 563kB/s]\n",
      "model.safetensors.index.json: 100%|██████████| 20.9k/20.9k [00:00<00:00, 10.7MB/s]\n",
      "model-00001-of-00004.safetensors: 100%|██████████| 5.00G/5.00G [00:52<00:00, 95.0MB/s]\n",
      "Downloading shards:  25%|██▌       | 1/4 [00:52<02:38, 52.88s/it]/root/monperrus/.env/lib/python3.10/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 4982.95 MB. The target location /root/.cache/huggingface/hub only has 2937.33 MB free disk space.\n",
      "  warnings.warn(\n",
      "/root/monperrus/.env/lib/python3.10/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 4982.95 MB. The target location /root/.cache/huggingface/hub/models--google--gemma-7b-it/blobs only has 2937.33 MB free disk space.\n",
      "  warnings.warn(\n",
      "model-00002-of-00004.safetensors:  59%|█████▉    | 2.95G/4.98G [00:34<00:23, 86.3MB/s]\n",
      "Downloading shards:  25%|██▌       | 1/4 [01:27<04:22, 87.39s/it]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHF_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_pCrYiYEfFLtyzVicKytzytQAaYIVxqJVAh\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/gemma-7b-it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoogle/gemma-7b-it\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHF_TOKEN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite me a poem about Machine Learning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/monperrus/.env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u0